{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhar9571/Capstone-Project-Classification-ML---Data-Mobile-Price-Range-Dataset/blob/main/Capstone_Project_Classification_ML_Data_Mobile_Price_Range_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncDsAP0Gaoa"
      },
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRrZCGUAJYm"
      },
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJNUwmbgGyua"
      },
      "source": [
        "# **Project Summary -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAL6M7E0wAoH"
      },
      "source": [
        "**Introduction**:\n",
        "\n",
        "The aim of this machine learning classification project is to predict the likelihood of default payments by customers in Taiwan. By accurately estimating the probability of default, the project intends to provide valuable insights for risk management. The focus is on developing a model that surpasses traditional binary classification by incorporating the estimated probability of default. The evaluation of customer credit card payment default will be carried out using the K-S chart, which enables a comprehensive assessment of default risk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6K7xa23Elo4"
      },
      "source": [
        "# **GitHub Link -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1o69JH3Eqqn"
      },
      "source": [
        "https://github.com/dhar9571/Capstone-Project-Classification-ML---Data-Mobile-Price-Range-Dataset.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQaldy8SH6Dl"
      },
      "source": [
        "# **Problem Statement**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeJGUA3kjGy"
      },
      "source": [
        "This project addresses the critical problem of default payment by customers on credit card payments. Payment defaults can have a significant financial impact on both individuals and financial institutions. Therefore, accurate prediction of the probability of default can greatly aid risk management. While binary classification (credible or non-credible customers) is a common approach, this project goes beyond this and emphasizes the importance of estimating the probability of default to improve prediction accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDgbUHAGgjLW"
      },
      "source": [
        "# **General Guidelines** : -"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      },
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "\n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "\n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "\n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "\n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_i_v8NEhb9l"
      },
      "source": [
        "# ***Let's Begin !***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhfV-JJviCcP"
      },
      "source": [
        "## ***1. Know Your Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lxredqlCYt"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "\n",
        "#Libraries for EDA:\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "#Libraries for Feature Engineering and Model Training:\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, f_classif\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RnN4peoiCZX"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "\n",
        "df = pd.read_excel(\"C:\\\\Users\\\\dk957\\\\Downloads\\\\default of credit card clients.xls\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x71ZqKXriCWQ"
      },
      "source": [
        "### Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "outputs": [],
      "source": [
        "# Dataset First Look\n",
        "\n",
        "# Setting the display option to show all the features:\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBIi_osiCS2"
      },
      "source": [
        "### Dataset Rows & Columns count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "outputs": [],
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "print(f'This Dataset has {df.shape[0]} rows and {df.shape[1]} columns')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlHwYmJAmNHm"
      },
      "source": [
        "### Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35m5QtbWiB9F"
      },
      "source": [
        "#### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "print(f'This dataframe has {df.duplicated().sum()} duplicate observations')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoPl-ycgm1ru"
      },
      "source": [
        "#### Missing Values/Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "outputs": [],
      "source": [
        "# Missing Values/Null Values Count\n",
        "\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP2FVzXswAoX"
      },
      "source": [
        "**Observation**:\n",
        "\n",
        "This dataset does not have any missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "outputs": [],
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "# Setting up figure size:\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Plotting heatmap\n",
        "sns.heatmap(df.isna(), yticklabels=False, cbar=True, cmap='viridis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE2zij7PwAoX"
      },
      "source": [
        "**Observation**:\n",
        "\n",
        "As per above heatmap, we can clearly see that there is no missing/null value exists in the  dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0kj-8xxnORC"
      },
      "source": [
        "### What did you know about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfoNAAC-nUe_"
      },
      "source": [
        "1. This Dataset has 30000 rows and 25 columns\n",
        "2. The dataset has 15 numerical and 10 categorical features\n",
        "3. The dataset has no duplicate values\n",
        "4. The dataset does not have any missing/null values\n",
        "5. This dataset does not have any feature with 'object' datatype as all the features are already converted to integer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      },
      "source": [
        "## ***2. Understanding Your Variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "\n",
        "for x in df.columns:\n",
        "    print(x, end=\" , \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe\n",
        "\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTbrJXOngz2"
      },
      "source": [
        "### Variables Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJV4KIxSnxay"
      },
      "source": [
        "**ID**: This column represents the unique identifier for each individual in the dataset. It is likely a numerical value but can be treated as categorical if it does not carry any meaningful numerical information.\n",
        "\n",
        "**LIMIT_BAL**: This column represents the credit limit of the individual's credit card. It is a numerical feature.\n",
        "\n",
        "**SEX**: This column represents the gender of the individual. It is a categorical feature.\n",
        "\n",
        "**EDUCATION**: This column represents the educational background of the individual. It is a categorical feature.\n",
        "\n",
        "**MARRIAGE**: This column represents the marital status of the individual. It is a categorical feature.\n",
        "\n",
        "**AGE**: This column represents the age of the individual. It is a numerical feature.\n",
        "\n",
        "**PAY_0 to PAY_6**: These columns represent the repayment status of the individual for the respective months. They indicate whether the individual made timely payments or had delayed payments. They are categorical features.\n",
        "\n",
        "**BILL_AMT1 to BILL_AMT6**: These columns represent the amount of bill statement for the respective months. They are numerical features.\n",
        "\n",
        "**PAY_AMT1 to PAY_AMT6**: These columns represent the amount of previous payments made by the individual for the respective months. They are numerical features.\n",
        "\n",
        "**default payment next month**: This column represents whether the individual defaulted on the credit card payment in the next month. It is the target variable and can be treated as a categorical feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3PMJOP6ngxN"
      },
      "source": [
        "### Check Unique Values for each variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "outputs": [],
      "source": [
        "df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dauF4eBmngu3"
      },
      "source": [
        "## 3. ***Data Wrangling***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKJF3rekwFvQ"
      },
      "source": [
        "### Data Wrangling Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdyYSaKZwAoi"
      },
      "outputs": [],
      "source": [
        "# Removing ID feature as it has unique identifiers which does not have valuable affect on output feature:\n",
        "\n",
        "df.drop(columns=[\"ID\"],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xflZqcjMwAoi"
      },
      "outputs": [],
      "source": [
        "# Checking unique values of EDUCATION categorical feature:\n",
        "\n",
        "df[\"EDUCATION\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sinBebRrwAoi"
      },
      "outputs": [],
      "source": [
        "# Checking unique values of MARRIAGE categorical feature:\n",
        "\n",
        "df[\"MARRIAGE\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSa1f5Uengrz"
      },
      "source": [
        "### What all manipulations have you done and insights you found?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbyXE7I1olp8"
      },
      "source": [
        "1. Removed ID column as it has unique identifiers which are not much important\n",
        "2. As the dataset does not have any duplicate and null values, much data wrangling is not required"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8Ens_Soomf"
      },
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOQAZs5pc--"
      },
      "source": [
        "### Chart - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v_ESjsspbW7",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Chart - 1 LIMIT_BAL vs SEX wise Default_Payment_Next_Month\n",
        "\n",
        "ax = sns.barplot(x=df[\"default payment next month\"],y=df[\"LIMIT_BAL\"],hue=df[\"SEX\"])\n",
        "\n",
        "for item  in ax.containers:\n",
        "    ax.bar_label(item)\n",
        "plt.xticks([0, 1],[\"No\",\"Yes\"])\n",
        "plt.xlabel(\"Default Payment Next Month\")\n",
        "plt.title(\"LIMIT_BAL vs SEX wise Default_Payment_Next_Month\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5QZ13OEpz2H"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESiWehPqBRc"
      },
      "source": [
        "Bar chart allows for easy comparison among different categories, making it possible to see patterns, trends, and relationships."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_j1G7yiqdRP"
      },
      "source": [
        "With the plot, it is clearly visible that:\n",
        "\n",
        "1. The defaulters have less credit limit compared to the Non-Defaulters.\n",
        "2. There is not significance difference in the credit limits of Males and Femails."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "448CDAPjqfQr"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cspy4FjqxJW"
      },
      "source": [
        "Based on the information of credit limit, it may become easy to interpret the chances of payment defaults."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSlN3yHqYklG"
      },
      "source": [
        "### Chart - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "outputs": [],
      "source": [
        "# Chart - 2 Education Type vs Default_Payment_Next_Month\n",
        "\n",
        "# Setting up plot size:\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "aa = sns.barplot(hue = df[\"default payment next month\"], x=df[\"EDUCATION\"], y = df[\"LIMIT_BAL\"])\n",
        "\n",
        "for value in aa.containers:\n",
        "    aa.bar_label(value)\n",
        "\n",
        "plt.title(\"Education Type vs Default_Payment_Next_Month\")\n",
        "plt.ylabel(\"LIMIT_BAL\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6dVpIINYklI"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aaW0BYyYklI"
      },
      "source": [
        "Bar chart allows for easy comparison among different categories, making it possible to see patterns, trends, and relationships."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijmpgYnKYklI"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSx9atu2YklI"
      },
      "source": [
        "1. Education type 1 defaulters have the highest LIMIT_BAL.\n",
        "2. Education type 0 has no defaulters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JiQyfWJYklI"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcBbebzrYklV"
      },
      "source": [
        "With the information on wise defaulters wise LIMIT_BAL as per Education Type, it would facilitate future prediction for the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZwBNRUuwAot"
      },
      "source": [
        "### Chart - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRX0IP30wAou"
      },
      "outputs": [],
      "source": [
        "# Chart - 3 Education type wise Male and Female Counts\n",
        "\n",
        "sns.countplot(x=df[\"EDUCATION\"], hue=df[\"SEX\"])\n",
        "plt.title(\"Education type wise Male and Female Counts\")\n",
        "plt.xlabel(\"Education Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY-zK8aywAou"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqyZLnlLwAov"
      },
      "source": [
        "Bar chart allows for easy comparison among different categories, making it possible to see patterns, trends, and relationships."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJOTREAVwAov"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvw9pKIkwAow"
      },
      "source": [
        "1. Education type 1, 2 and 3 have the highest count of Males and Females.\n",
        "2. In all of the education types, number of females are higher compared to males."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF7R1AVDwAow"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gb8xzhxwAox"
      },
      "source": [
        "With the information on male and female counts as per education type, it would be beneficial to make amendments in credit policies accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM7whBJCYoAo"
      },
      "source": [
        "### Chart - 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "outputs": [],
      "source": [
        "# Chart - 4 Distribution of Age with Payment Defaults\n",
        "\n",
        "# Creating seperate dataframes for No Default and Default types:\n",
        "\n",
        "default_0 = df[df['default payment next month'] == 0]\n",
        "default_1 = df[df['default payment next month'] == 1]\n",
        "\n",
        "# Plotting histogram:\n",
        "\n",
        "plt.hist(default_0['AGE'], bins=10, alpha=0.5, label='No Default')\n",
        "plt.hist(default_1['AGE'], bins=10, alpha=0.5, label='Default')\n",
        "\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Age with Payment Defaults')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fge-S5ZAYoAp"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dBItgRVYoAp"
      },
      "source": [
        "Histograms provide a visual representation of the distribution of data. They show how data is spread across different intervals or bins, allowing us to quickly understand the overall shape, central tendency and spread of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85gYPyotYoAp"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jstXR6OYoAp"
      },
      "source": [
        "1. Most of the defaulters are in the age group 20 - 35 (approx).\n",
        "2. The data distribution is a little skewed to the right."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoGjAbkUYoAp"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      },
      "source": [
        "Age wise Defaulters information is very important from a business point of view. Age group 20-35 should be taken into consideration before credit allowance as these have highest probability of payment defaults."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Of9eVA-YrdM"
      },
      "source": [
        "### Chart - 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "outputs": [],
      "source": [
        "# Chart - 5 Marriage vs. Default Payment Next Month\n",
        "\n",
        "#Setting up figure size:\n",
        "\n",
        "plt.figure(figsize = (10, 6))\n",
        "\n",
        "ab = sns.countplot(hue=df[\"default payment next month\"], x = df[\"MARRIAGE\"])\n",
        "\n",
        "for item in ab.containers:\n",
        "    ab.bar_label(item)\n",
        "plt.title(\"Marriage vs. Default Payment Next Month\")\n",
        "plt.xlabel(\"Marriage Status\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iky9q4vBYrdO"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJRCwT6DYrdO"
      },
      "source": [
        "Bar chart allows for easy comparison among different categories, making it possible to see patterns, trends, and relationships."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6T5p64dYrdO"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      },
      "source": [
        "1. Almost the defaulters belong to MARRIAGE status 1 and 2. Rest of the marriage types 0 and 3 have almost no defaulters.\n",
        "2. Marriage Status 1 and 2 have almost same number of defaulters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Ehk30pYrdP"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLNxxz7MYrdP"
      },
      "source": [
        "With marriage type information, it would become easier to interpret the chances of default payments from business point of view."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bamQiAODYuh1"
      },
      "source": [
        "### Chart - 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIJwrbroYuh3",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Chart - 6 Checking Linear Relationship between LIMIT_BAL and other numerical features\n",
        "\n",
        "# Creating a for loop to create multiple scatterplot with LIMIT_BAL feature on X-Axis and other numerical features on Y-Axis.\n",
        "\n",
        "for item in ['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
        "             'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']:\n",
        "    sns.scatterplot(x=df[\"LIMIT_BAL\"], y=df[item])\n",
        "    plt.title(f\"Association between LIMIT_BAL and {item}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcxuIMRPYuh3"
      },
      "source": [
        "Scatterplots allow us to visually identify any patterns, trends, or relationships between the variables. This can help determine if the variables are positively or negatively related, or if there is no apparent relationship."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwzvFGzlYuh3"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyqkiB8YYuh3"
      },
      "source": [
        "1. The numerical features are not much linearly correlated with the LIMIT_BAL feature.\n",
        "2. There is no normality in the spread of the data points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYpmQ266Yuh3"
      },
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      },
      "source": [
        "If the numerical features have linear relationship, it can help to make better predictions on the new/unseen dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC_X3p0fY2L0"
      },
      "source": [
        "### Chart - 7 - Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "outputs": [],
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "corr = df.corr()\n",
        "\n",
        "#Setting up plot size:\n",
        "plt.figure(figsize=(20,14))\n",
        "\n",
        "sns.heatmap(corr, annot=True)\n",
        "plt.title(\"Correlation Heatmap\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      },
      "source": [
        "A correlation heatmap allows us to quickly identify patterns and relationships between variables. By using colors to represent correlation values, we can easily spot variables that are positively correlated (high values represented by a certain color) or negatively correlated (low values represented by a different color). This visual representation helps to identify which variables are strongly related and which are not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfSqtnDqZNRR"
      },
      "source": [
        "1. BILL_AMT1 to BILL_AMT6 are highely correlated with each other.\n",
        "2. PAY_0 to PAY_6 have high correlation with each other.\n",
        "3. Remaining features do not have any strong correlation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q29F0dvdveiT"
      },
      "source": [
        "### Chart - 8 - Pair Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "outputs": [],
      "source": [
        "# Pair Plot visualization code\n",
        "\n",
        "# Creating an instance of the pairplot:\n",
        "pairplot = sns.pairplot(df)\n",
        "\n",
        "# Creating pairplot with image settings to avoid tiny pairplots:\n",
        "pairplot.savefig(\"pairplot.png\", dpi=300)\n",
        "\n",
        "plt.title(\"Pair Plot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXh0U9oCveiU"
      },
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMmPjTByveiU"
      },
      "source": [
        "Pair plots allow us to visually explore the relationships between variables in a dataset. By examining the scatter plots, we can quickly identify patterns, trends, and associations between pairs of variables. This can help us understand the data and identify potential relationships that may require further investigation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22aHeOlLveiV"
      },
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPQ8RGwHveiV"
      },
      "source": [
        "1. The numerical features are not much linearly correlated with the LIMIT_BAL feature.\n",
        "2. There is no normality in the spread of the data points.\n",
        "3. BILL_AMT1 to BILL_AMT6 are highely correlated with each other.\n",
        "4. PAY_0 to PAY_6 have high correlation with each other.\n",
        "5. Remaining features do not have any strong correlation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ATYxFrGrvw"
      },
      "source": [
        "## ***5. Hypothesis Testing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      },
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yEUt7NnHlrM"
      },
      "source": [
        "### Hypothetical Statement - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI9ZP0laH0D-"
      },
      "source": [
        "Null Hypothesis: There is no difference between LIMIT_BAL between Males in Females. (means are same)\n",
        "\n",
        "Alternate Hypothesis: There is significant difference between LIMIT_BAL between Males in Females. (means are not same)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I79__PHVH19G"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# importing required library:\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "males_data = df[df[\"SEX\"] == 1][\"LIMIT_BAL\"]\n",
        "females_data = df[df[\"SEX\"] == 2][\"LIMIT_BAL\"]\n",
        "\n",
        "# Applying ttest:\n",
        "\n",
        "t_statistic, p_value = stats.ttest_ind(males_data, females_data)\n",
        "\n",
        "# Seting up the significance level\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "print(f't_statistic is {t_statistic}')\n",
        "print(f'p_value is {p_value}')\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference in LIMIT_BAL between males and females.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference in LIMIT_BAL between males and females.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou-I18pAyIpj"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2U0kk00ygSB"
      },
      "source": [
        "Performed t-test for obtain the p-value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF3858GYyt-u"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO4K0gP5y3B4"
      },
      "source": [
        "When we have a categorical feature with 2 classes and one numerical feature, we can peform t-test to compare the means of those classes basis on the numerical feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkNEHfATwApJ"
      },
      "source": [
        "##### Observation:\n",
        "\n",
        "As per above test results, we can confirm that LIMIT_BAL for males and females are not the same which we also observed through the plot below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKjxh8lbwApL"
      },
      "source": [
        "![image-2.png](attachment:image-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_0_7-oCpUZd"
      },
      "source": [
        "### Hypothetical Statement - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwyV_J3ipUZe"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      },
      "source": [
        "Null Hypothesis: All education type have same LIMIT_BAL. (means are same)\n",
        "\n",
        "Alternate Hypothesis: There is a significant difference in LIMIT_BAL among all education types. (means are not same)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yB-zSqbpUZe"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Extracting data for each education type\n",
        "\n",
        "education_type_1 = df[df[\"EDUCATION\"] == 1][\"LIMIT_BAL\"]\n",
        "education_type_2 = df[df[\"EDUCATION\"] == 2][\"LIMIT_BAL\"]\n",
        "education_type_3 = df[df[\"EDUCATION\"] == 3][\"LIMIT_BAL\"]\n",
        "education_type_4 = df[df[\"EDUCATION\"] == 4][\"LIMIT_BAL\"]\n",
        "\n",
        "# Performing one-way ANOVA\n",
        "\n",
        "f_statistic, p_value = stats.f_oneway(education_type_1, education_type_2, education_type_3, education_type_4)\n",
        "\n",
        "# Seting up the significance level\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "print(f'f_statistic is {f_statistic}')\n",
        "print(f'p_value is {p_value}')\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference in LIMIT_BAL among education types.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference in LIMIT_BAL among education types.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUvejAfpUZe"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLDrPz7HpUZf"
      },
      "source": [
        "Performed ANOVA (Analysis of Variance) test to obtain the P-value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd15vwWVpUZf"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOGYyiBpUZf"
      },
      "source": [
        "ANOVA is suitable for comparing means when we have more than two classes in categorical variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MAL0m8hwApU"
      },
      "source": [
        "##### Observation:\n",
        "\n",
        "As per above test results, we can confirm that LIMIT_BAL all the education types are not the same which we also observed through the plot below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQIGzyLJwApU"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn_IUdTipZyH"
      },
      "source": [
        "### Hypothetical Statement - 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49K5P_iCpZyH"
      },
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gWI5rT9pZyH"
      },
      "source": [
        "Null Hypothesis: The number of males and females in all education types are same. (Means are same)\n",
        "\n",
        "Alternate Hypothesis: There is a significant difference between the number of males and females with respect to the different education types. (Means are not same)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nff-vKELpZyI"
      },
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "outputs": [],
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Creating a contingency table\n",
        "contingency_table = pd.crosstab(df[\"EDUCATION\"], df[\"SEX\"])\n",
        "\n",
        "# Performing chi-square test of independence\n",
        "chi2_stat, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "# Seting up the significance level\n",
        "\n",
        "alpha = 0.05\n",
        "\n",
        "print(f'chi2_stat is {chi2_stat}')\n",
        "print(f'p_value is {p_value}')\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference between the number of males and females across education types.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference between the number of males and females across education types.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLW572S8pZyI"
      },
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytWJ8v15pZyI"
      },
      "source": [
        "Performed Chi_Square test to obtain the P-Value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWbDXHzopZyI"
      },
      "source": [
        "##### Why did you choose the specific statistical test?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M99G98V6pZyI"
      },
      "source": [
        "Chi_Square test is suitable for analyzing categorical data and determining if there is a significant association between two variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gksr3rYIwApY"
      },
      "source": [
        "#### Observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbUeyOrVwApY"
      },
      "source": [
        "As per above test results, we can confirm that the number of males and females in all education types are not the same, which we also observed through the plot below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUa80MGVwApZ"
      },
      "source": [
        "![image-2.png](attachment:image-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLjJCtPM0KBk"
      },
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id1riN9m0vUs"
      },
      "source": [
        "### 1. Handling Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6w2CzZf04JK",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "# Creating a For Loop to construct box plots for each feature:\n",
        "\n",
        "for column in df.columns:\n",
        "    sns.boxplot(df[column])\n",
        "    plt.title(column)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3IugJAawApb"
      },
      "source": [
        "#### Observation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPsCOiZ3wApb"
      },
      "source": [
        "All the numerical features have outliers which needs to be handled before feeding the data to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paeOo1jwwApb"
      },
      "outputs": [],
      "source": [
        "# Creating a list of numerical features from the dataframe:\n",
        "\n",
        "num_features = ['LIMIT_BAL', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1',\n",
        "                'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
        "\n",
        "# Creating a for loop to remove the outliers from numerical features using Inter Quertile Range:\n",
        "\n",
        "for column in num_features:\n",
        "    q1, q3 = np.percentile(df[column],[25,75])\n",
        "    iqr = q3-q1\n",
        "    lower_range = q1-(1.5*iqr)\n",
        "    upper_range = q3+(1.5*iqr)\n",
        "\n",
        "    df[column] = df[column].apply(lambda x: np.nan if x<lower_range or x>upper_range else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "P_9Bh9-5wApb"
      },
      "outputs": [],
      "source": [
        "# Again checking the outliers using boxplots for numerical features:\n",
        "\n",
        "for column in num_features:\n",
        "    sns.boxplot(df[column])\n",
        "    plt.title(column)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9MuM6aGwApc"
      },
      "source": [
        "#### Observation:\n",
        "\n",
        "Most of the outliers have been removed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "578E2V7j08f6"
      },
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bak6t0xQwApc"
      },
      "source": [
        "**Technique used**: Interquartile range (IQR) method\n",
        "\n",
        "**Reason**: Used this technique as the Interquartile range (IQR) method is a robust method to detect and remove outliers from a dataset. It is useful when the data has a non-normal distribution and contains extreme values or outliers. The IQR method calculates the range between the first quartile (Q1) and third quartile (Q3) of the data, and then identifies outliers as any data points outside of the range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiyOF9F70UgQ"
      },
      "source": [
        "### 2. Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "outputs": [],
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "# Checking missing values after removing the outliers:\n",
        "\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANtswczowApd"
      },
      "outputs": [],
      "source": [
        "# Creating a for loop to replace all the null/missing of numerical feature values with the mean:\n",
        "\n",
        "for column in num_features:\n",
        "    df[column].fillna(np.mean(df[column]),inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krvoQ-2awApe"
      },
      "outputs": [],
      "source": [
        "# Again checking missing values:\n",
        "\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wuGOrhz0itI"
      },
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ixusLtI0pqI"
      },
      "source": [
        "Replaced all the null/missing values with column means for all the numerical features. Mean is used to fill null values when the features are numerical and there are no outliers present."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89xtkJwZ18nB"
      },
      "source": [
        "### 3. Categorical Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67NQN5KX2AMe"
      },
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDaue5h32n_G"
      },
      "source": [
        "1. All the feature have numerical values. Therefore, Label encoding is not required.\n",
        "2. Created Dummy Variables for ordianal features: PAY_0, PAY_2, PAY_3, PAY_4, PAY_5, PAY_6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4ZGbvBvwApj"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bT-KWmIrwApj"
      },
      "outputs": [],
      "source": [
        "df = pd.get_dummies(df,columns=[\"PAY_0\",\"PAY_2\",\"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwf50b-R2tYG"
      },
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9jKVxE06BC1"
      },
      "source": [
        "No Textual Data is present."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      },
      "source": [
        "### 4. Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_Z98GrawApl"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNs49UCgwApl"
      },
      "outputs": [],
      "source": [
        "# Creating seperate dataframe for dependent and independent features:\n",
        "\n",
        "X = df.drop([\"default payment next month\"],axis=1)\n",
        "y = df[\"default payment next month\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "outputs": [],
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "# Creating an instance of SelectKBest Class:\n",
        "\n",
        "selectkbest = SelectKBest(score_func= mutual_info_classif, k=81)\n",
        "\n",
        "# Fitting the instance on dataframe:\n",
        "\n",
        "best_features = selectkbest.fit(X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvkhZvs8wApm"
      },
      "outputs": [],
      "source": [
        "# Creating a dataframe for the feature scores:\n",
        "\n",
        "scores = pd.DataFrame(best_features.scores_, columns = [\"Scores\"])\n",
        "\n",
        "# Creating another dataframe for column names:\n",
        "\n",
        "features = pd.DataFrame(X.columns, columns = [\"Feature\"])\n",
        "\n",
        "# Concatinating both the dataframes to get each feature along with its score:\n",
        "\n",
        "feature_score = pd.concat([features, scores], axis=1)\n",
        "\n",
        "# Sorting the features as per the scores in decending order:\n",
        "\n",
        "feature_score.sort_values(by=\"Scores\", axis = 0, ascending=False, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g66xzzllwApn"
      },
      "outputs": [],
      "source": [
        "feature_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57jFjEZDwApn"
      },
      "outputs": [],
      "source": [
        "# Checking scores of each feature:\n",
        "\n",
        "feature_score.head(60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMTyAFK0wApo"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ci9Kmk8wApo"
      },
      "outputs": [],
      "source": [
        "# Dropping unimportant features from the dataset:\n",
        "\n",
        "df = df.drop(columns=[\"EDUCATION_2\",\"EDUCATION_3\",\"PAY_6_6\",\"PAY_3_-2\",\"PAY_2_-2\",\"EDUCATION_5\",\"PAY_AMT5\",\"PAY_2_4\",\"PAY_6_4\",\"PAY_AMT6\"],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEMng2IbBLp7"
      },
      "source": [
        "##### What all feature selection methods have you used?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      },
      "source": [
        "Used **SelectKBest** feature selection technique from **sklearn.feature_select** module."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      },
      "source": [
        "##### Which all features you found important and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGgaEstsBnaf"
      },
      "source": [
        "As per the highest SelectKBest feature scores, below features are found to be important as they carry the highest and moderate score.\n",
        "\n",
        "['PAY_0', 'PAY_2', 'LIMIT_BAL', 'PAY_3', 'PAY_4', 'PAY_AMT1',\n",
        "       'PAY_5', 'PAY_6', 'PAY_AMT3', 'PAY_AMT2', 'PAY_AMT4', 'PAY_AMT6',\n",
        "       'PAY_AMT5', 'SEX']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNVZ9zx19K6k"
      },
      "source": [
        "### 5. Data Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqoHp30x9hH9"
      },
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "source": [
        "Data tranformation is not required"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMDnDkt2B6du"
      },
      "source": [
        "### 6. Data Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dL9LWpySC6x_",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Scaling your data\n",
        "\n",
        "# Creating an instance of standardscaler class:\n",
        "\n",
        "standard = StandardScaler()\n",
        "\n",
        "# Creating a seperate dataframe for numerical and categorical features:\n",
        "\n",
        "num_X = df[[\"LIMIT_BAL\",\"PAY_AMT1\",\"PAY_AMT3\",\"PAY_AMT2\",\"PAY_AMT4\",\"PAY_AMT6\",\"PAY_AMT5\"]]\n",
        "cat_X = df.drop(columns=[\"LIMIT_BAL\",\"PAY_AMT1\",\"PAY_AMT3\",\"PAY_AMT2\",\"PAY_AMT4\",\"PAY_AMT6\",\"PAY_AMT5\"],axis=1)\n",
        "\n",
        "# Fitting and transforming the independent feature data:\n",
        "\n",
        "num_X = standard.fit_transform(num_X, y)\n",
        "\n",
        "# Converting num_X data into dataframe:\n",
        "\n",
        "num_X = pd.DataFrame(num_X, columns=[\"LIMIT_BAL\",\"PAY_AMT1\",\"PAY_AMT3\",\"PAY_AMT2\",\"PAY_AMT4\",\"PAY_AMT6\",\"PAY_AMT5\"])\n",
        "\n",
        "# concatinating the categorical and scaled numerical features:\n",
        "\n",
        "df_scaled = pd.concat([num_X,cat_X],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiiVWRdJDDil"
      },
      "source": [
        "##### Which method have you used to scale you data and why?\n",
        "\n",
        "Used StandardScaler from sklearn.preprocessing module to standardize the data for Logistic Regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UUpS68QDMuG"
      },
      "source": [
        "### 7. Dimesionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kexQrXU-DjzY"
      },
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      },
      "source": [
        "Dimensionality Reduction is not required as dataset have only 25 features including dependent feature. Therefore, Dimensionlity Reduction will not provide much benefit in predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhH2vgX9EjGr"
      },
      "source": [
        "### 8. Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QixS14WLwApu"
      },
      "outputs": [],
      "source": [
        "# Creating seperate dataframe for dependent and independent features:\n",
        "\n",
        "X = df_dummy.drop(columns=[\"default payment next month\"],axis=1)\n",
        "y = df_dummy[\"default payment next month\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "outputs": [],
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "\n",
        "# train test split for standardized data:\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca,y,test_size = 0.2, random_state = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjKvONjwE8ra"
      },
      "source": [
        "##### What data splitting ratio have you used and why?\n",
        "\n",
        "Used 4:1 ratio of train and test data as more training data will provide better predictions on unseen/test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1XJ9OREExlT"
      },
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "outputs": [],
      "source": [
        "# Checking Imbalanced Dataset:\n",
        "\n",
        "df_dummy[\"default payment next month\"].value_counts().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "yva6pC2QwAp0"
      },
      "outputs": [],
      "source": [
        "ad = sns.barplot(x=df_dummy[\"default payment next month\"].value_counts().reset_index()[\"index\"],y=df_dummy[\"default payment next month\"].value_counts().reset_index()[\"default payment next month\"])\n",
        "\n",
        "plt.title(\"Distribution of Each Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xlabel(\"Class\")\n",
        "\n",
        "for item in ad.containers:\n",
        "    ad.bar_label(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFOzZv6IFROw"
      },
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeKDIv7pFgcC"
      },
      "source": [
        "The dataset is highly imbalanced as 0 class has almost 78% distribution and 1 class has only 22% distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAg9agCawAp1"
      },
      "outputs": [],
      "source": [
        "# Handling the Imbalanced Dataset:\n",
        "\n",
        "# importing required libraries:\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Creating an instance of this class:\n",
        "\n",
        "imb = SMOTE(random_state = 1)\n",
        "\n",
        "# Fitting the data:\n",
        "\n",
        "X_train_new, y_train_new = imb.fit_resample(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNy4H_98wAp2"
      },
      "outputs": [],
      "source": [
        "X_train_new.shape, y_train_new.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lmbrs7BYwAp3"
      },
      "outputs": [],
      "source": [
        "y_train_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gk1pSOPzwAp3"
      },
      "outputs": [],
      "source": [
        "y_train_new.value_counts().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyvrEn45wAp3"
      },
      "outputs": [],
      "source": [
        "# Again checking the class distribution for balanced dataset:\n",
        "\n",
        "ac = sns.barplot(x=y_train_new.value_counts().reset_index()[\"index\"],y=y_train_new.value_counts().reset_index()[\"default payment next month\"])\n",
        "\n",
        "# Creating a For loop to show bar values:\n",
        "\n",
        "for item in ac.containers:\n",
        "    ac.bar_label(item)\n",
        "\n",
        "plt.title(\"Class distribution\")\n",
        "plt.ylabel(\"Counts\")\n",
        "plt.xlabel(\"Class\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtRb1jrRwAp4"
      },
      "source": [
        "**Observation**:\n",
        "\n",
        "The dataset is balanced as number of both the classes are equal now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIqpNgepFxVj"
      },
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbet1HwdGDTz"
      },
      "source": [
        "Used Random-Over_sampling technique to handle the dataset as the number of observations are 30000 which is considered as large dataset. Choosing Under_Sampling may cause loss of information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q_e7JaowAp5"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming your data is stored in X as a numpy array or pandas DataFrame\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Create an instance of PCA\n",
        "pca = PCA(n_components=3)  # Specify the number of components you want to keep\n",
        "\n",
        "# Apply PCA to the scaled data\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Access the principal components (eigenvectors)\n",
        "principal_components = pca.components_\n",
        "\n",
        "# Access the explained variance ratio\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "# Print the explained variance ratio for each component\n",
        "for i, ratio in enumerate(explained_variance_ratio):\n",
        "    print(f\"Explained Variance Ratio of Component {i+1}: {ratio}\")\n",
        "\n",
        "# Access the singular values (eigenvalues)\n",
        "singular_values = pca.singular_values_\n",
        "\n",
        "# Print the singular values\n",
        "print(\"Singular Values:\")\n",
        "print(singular_values)\n",
        "\n",
        "# Access the projected data onto the principal components\n",
        "X_projected = pca.inverse_transform(X_pca)\n",
        "\n",
        "# You can now use X_pca or X_projected for further analysis or visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK2M1KndwAp5"
      },
      "outputs": [],
      "source": [
        "X_pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJLDOAM0wAp5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfCC591jGiD4"
      },
      "source": [
        "## ***7. ML Model Implementation***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      },
      "source": [
        "### ML Model - 1 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Creating an instance of the class:\n",
        "\n",
        "logistic = LogisticRegression()\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "logistic.fit(X_train_new,y_train_new)\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "logistic_y_pred = logistic.predict(X_test)\n",
        "\n",
        "print(logistic_y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArJBuiUVfxKd"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "print(classification_report(y_test, logistic_y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qY1EAkEfxKe"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy61ujd6fxKe",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Defining hyperparameters:\n",
        "\n",
        "parameters = {\"penalty\":[\"l1\",\"l2\",\"ElasticNet\"], \"C\": [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100],\n",
        "              \"max_iter\":[100,200,300,400,500]}\n",
        "\n",
        "# Creating an instance of gridsearchcv:\n",
        "\n",
        "logistic_grid = GridSearchCV(estimator=logistic, param_grid=parameters, scoring=\"accuracy\", cv=5)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "logistic_grid.fit(X_train_new, y_train_new)\n",
        "\n",
        "# Reviewing optimal values for hyperparameters:\n",
        "\n",
        "logistic_grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZys0zFZwAp8"
      },
      "outputs": [],
      "source": [
        "# Predict on the model\n",
        "\n",
        "logisticgrid_y_pred = logistic_grid.predict(X_test)\n",
        "\n",
        "# Evaluating scores:\n",
        "\n",
        "print(classification_report(y_test, logisticgrid_y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "negyGRa7fxKf"
      },
      "source": [
        "Used GridSearchCV technique to find the optimal values of hyperparameters as GridSearchCV performs an exhaustive search over a predefined set of hyperparameter values. It considers all possible combinations of the provided hyperparameters, allowing us to explore different combinations in a systematic and organized manner including cross-validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfvqoZmBfxKf"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaLui8CcfxKf"
      },
      "source": [
        "There is no improvement after hyperparameter tuning as sometimes, the default values of hyperparameters works best for the algorithm to fit the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      },
      "source": [
        "### ML Model - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "outputs": [],
      "source": [
        "# ML Model - 2 Implementation\n",
        "\n",
        "# Creating an instance of the class:\n",
        "\n",
        "decision = DecisionTreeClassifier()\n",
        "\n",
        "# Fitting the model to the data\n",
        "\n",
        "decision.fit(X_train_new, y_train_new)\n",
        "\n",
        "# Predicting on unseen data:\n",
        "\n",
        "decision_y_pred = decision.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PkwO5GWwAqB"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKkJFT5PwAqB"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "print(classification_report(y_test, decision_y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn0EOfS6psJ2",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# ML Model - 2 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Defining hyperparameters:\n",
        "\n",
        "parameters_decision = {\"criterion\":[\"gini\",\"entropy\",\"log_loss\"], \"splitter\": [\"best\",\"random\"], \"max_depth\":[3,5,7,9,10,12,15,20,30,32,35,38,40]}\n",
        "\n",
        "# Creating an instance of gridsearchcv:\n",
        "\n",
        "decision_grid = GridSearchCV(estimator=decision, param_grid=parameters_decision, scoring=\"accuracy\", cv=5)\n",
        "\n",
        "# Fiting the Algorithm\n",
        "\n",
        "decision_grid.fit(X_train_new, y_train_new)\n",
        "\n",
        "# Reviewing optimal values for hyperparameters:\n",
        "\n",
        "decision_grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMpm-Gi6wAqC"
      },
      "outputs": [],
      "source": [
        "# Predict on the model\n",
        "\n",
        "decisiongrid_y_pred = decision_grid.predict(X_test)\n",
        "\n",
        "# Evaluating scores:\n",
        "\n",
        "print(classification_report(y_test, decisiongrid_y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAih1iBOpsJ2"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74yRdG6UpsJ3"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      },
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fze-IPXLpx6K"
      },
      "source": [
        "### ML Model - 3 RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "outputs": [],
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Creating an instance of the class:\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators=20, oob_score = True, n_jobs = 1, random_state = 42, max_features = None,\n",
        "                                min_samples_leaf = 10)\n",
        "\n",
        "# Fitting the model to the data\n",
        "\n",
        "forest.fit(X_train_new, y_train_new)\n",
        "\n",
        "# Predicting on unseen data:\n",
        "\n",
        "forest_y_pred = forest.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AN1z2sKpx6M"
      },
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIY4lxxGpx6M",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "print(classification_report(y_test, forest_y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96ZWeXtWwAqH"
      },
      "outputs": [],
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Creating an instance of the class:\n",
        "\n",
        "boost = XGBClassifier()\n",
        "\n",
        "# Fitting the model to the data\n",
        "\n",
        "boost.fit(X_train_new, y_train_new)\n",
        "\n",
        "# Predicting on unseen data:\n",
        "\n",
        "boost_y_pred = boost.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eTUiQ5qwAqH"
      },
      "outputs": [],
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "print(classification_report(y_test, boost_y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PIHJqyupx6M"
      },
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSVXuaSKpx6M",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Defining hyperparameters:\n",
        "\n",
        "parameters_forest = {\"n_estimators\":[20],oob_score=True, \"criterion\":[\"gini\",\"entropy\",\"log_loss\"], \"max_depth\":[10,20,30,35,38,40]}\n",
        "\n",
        "# Creating an instance of gridsearchcv:\n",
        "\n",
        "forest_grid = GridSearchCV(estimator=forest, param_grid=parameters_forest, scoring=\"accuracy\", cv=5)\n",
        "\n",
        "# Fiting the Algorithm\n",
        "\n",
        "forest_grid.fit(X_train_new, y_train_new)\n",
        "\n",
        "# Reviewing optimal values for hyperparameters:\n",
        "\n",
        "forest_grid.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnWq3ZMwwAqI"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_train, forest_grid.predict(X_train)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGvcvNz2wAqJ"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, forest_grid.predict(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NU2hoaB6wAqJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-qAgymDpx6N"
      },
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQMffxkwpx6N"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-hykwinpx6N"
      },
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzVzZC6opx6N"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_CCil-SKHpo"
      },
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHVz9hHDKFms"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBFFvTBNJzUa"
      },
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvGl1hHyA_VK"
      },
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnvVTiIxBL-C"
      },
      "source": [
        "Answer Here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyNgTHvd2WFk"
      },
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH5McJBi2d8v"
      },
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "outputs": [],
      "source": [
        "# Save the File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      },
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "outputs": [],
      "source": [
        "# Load the File and predict unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kee-DAl2viO"
      },
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xbcl9XCBwAqU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      },
      "source": [
        "Write the conclusion here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIfDvo9L0UH2"
      },
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}